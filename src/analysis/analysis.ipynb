{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from src.classes.database.offer import MongoOffer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "token_list = [tokenizer.tokenize(x.selling) for x in MongoOffer.objects()][0:100]\n",
    "tagged = nltk.pos_tag(token_list[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_all_words(token_list: list[list]) -> list:\n",
    "    words = set()\n",
    "    for sentence in token_list:\n",
    "        for word in sentence:\n",
    "            words.add(word)\n",
    "    return sorted(words)\n",
    "\n",
    "def next_word_occurrence(key: str, look_ahead: int, tokens: list[list]) -> dict:\n",
    "    counter = defaultdict(int)\n",
    "    for sentence in tokens:\n",
    "        for x in range(0, len(sentence)):\n",
    "            if key == sentence[x]: #if we find the key in a sentence\n",
    "                if (x+look_ahead) < len(sentence):\n",
    "                    counter[sentence[x+look_ahead]] += 1\n",
    "    return counter\n",
    "\n",
    "def p_next_word(given: str, looking: str, look_ahead: int, tokens: list[list]) -> float:\n",
    "    nwo: dict = next_word_occurrence(given, look_ahead, tokens)\n",
    "    return nwo[looking] / sum(nwo.values()) if nwo[looking] != 0 else 0\n",
    "\n",
    "def calculate_all_probabilities(tokens: list[list]) -> dict:\n",
    "    all_words = get_all_words(tokens)\n",
    "\n",
    "    #Generating a list of all words\n",
    "    word_canvas = {}\n",
    "    for word in all_words:\n",
    "        word_canvas[word] = None\n",
    "\n",
    "    p_word = word_canvas.copy()\n",
    "    for word in tqdm(p_word):\n",
    "        p_word[word] = [word_canvas.copy() for x in range(0,5)]\n",
    "        for x in range(0,5):\n",
    "            for sub_word in p_word[word][x].keys():\n",
    "                p_word[word][x][sub_word] = p_next_word(word, sub_word, x+1, tokens)\n",
    "                #print(f\"{word} | {str(x)} | {sub_word}: {p_word[word][x][sub_word]}\")\n",
    "\n",
    "\n",
    "    return p_word"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [00:18<00:00, 21.99it/s]\n"
     ]
    }
   ],
   "source": [
    "data = calculate_all_probabilities(token_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['i5'][0].values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "class Word:\n",
    "    def __init__(self, word: str):\n",
    "        self.word = word\n",
    "        self.p_of_next_word = [next_word_occurrence(word, x, token_list) for x in range(1,6)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = Word('i5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.p_of_next_word[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "p_of_next_word['word']['looking_for_word'][INDEX HERE OF LOOKAHEAD]\n",
    "return object like {occurrences: 1, probability: 0.5}\n",
    "\n",
    "word1\n",
    "    looking_for1\n",
    "        0: {occurenecs:1, probability: 0.5}\n",
    "        1:  {occurenecs:1, probability: 0.5}\n",
    "        2:  {occurenecs:0, probability: 5}\n",
    "    looking_for2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
