{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from src.classes.database.offer import MongoOffer\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "token_list = [tokenizer.tokenize(x.selling) for x in MongoOffer.objects()]\n",
    "direction = Enum('direction', ['FORWARD', 'BACKWARD', 'SELF'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_all_words(token_list: list[list]) -> list:\n",
    "    words = []\n",
    "    for sentence in token_list:\n",
    "        for word in sentence:\n",
    "            words.append(word)\n",
    "    return sorted(set(words))\n",
    "\n",
    "def next_word_occurrence(key: str, look_ahead: int, tokens: list[list]) -> dict:\n",
    "    counter = defaultdict(int)\n",
    "    for sentence in tokens:\n",
    "        for x in range(0, len(sentence)):\n",
    "            if key == sentence[x]: #if we find the key in a sentence\n",
    "                if (x+look_ahead) < len(sentence):\n",
    "                    counter[sentence[x+look_ahead]] += 1\n",
    "    return counter\n",
    "\n",
    "def p_next_word(given: str, looking: str, look_ahead: int, tokens: list[list]) -> float:\n",
    "    nwo: dict = next_word_occurrence(given, look_ahead, tokens)\n",
    "    return nwo[looking] / sum(nwo.values()) if nwo[looking] != 0 else 0\n",
    "\n",
    "# Old method, slow and not used anymore\n",
    "def calculate_all_probabilities(tokens: list[list], look_ahead) -> dict:\n",
    "    all_words = get_all_words(tokens)\n",
    "\n",
    "    #Generating a list of all words\n",
    "    word_canvas = defaultdict()\n",
    "    for word in all_words:\n",
    "        word_canvas[word] = None\n",
    "\n",
    "    p_word = word_canvas.copy()\n",
    "    for word in tqdm(p_word):\n",
    "        p_word[word] = [defaultdict(float) for x in range(0,look_ahead)]\n",
    "        for x in range(0,look_ahead):\n",
    "            for sub_word in all_words:\n",
    "                p = p_next_word(word, sub_word, x+1, tokens)\n",
    "                if p > 0:\n",
    "                    p_word[word][x][sub_word] = p_next_word(word, sub_word, x+1, tokens)\n",
    "                #print(f\"{word} | {str(x)} | {sub_word}: {p_word[word][x][sub_word]}\")\n",
    "    return p_word\n",
    "#data = calculate_all_probabilities(token_list, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HMaxtrix\n",
    "Used for storing all word occurrences in a 3 dimensional matrix\n",
    "\n",
    "### Data we can get from matrix\n",
    " 1. p(start, find) = probability that 'find' is a n-order forward word for 'start' | single cell value / sum of 'start' row\n",
    " 2. p(start, find) = probability that 'find' is a n-order backward word for 'start' | single cell value / sum of 'start' column\n",
    " 3. p(row_word) = probability that 'row word' will be a n-order forward word | sum of row / entire table sum\n",
    " 4. p(col_word) = probability that 'col word' will be a n-order backward word | sum of column / entire table sum\n",
    " 5. p(word, order) = probability that 'word' will be n-order word compared to the other orders| single cell value at order / all order values of that word tallied (through the table)\n",
    " 6.  p(word-row, order) = probability that 'word' will be n-order forward word | all of word-row order sum / all order values of that word-row\n",
    " 7. p(col-row, order) = probability that 'word' will be n-order backward word | all of word-col order sum / all order values of that word-col"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class HMatrix:\n",
    "    def __init__(self, verbose=False) -> None:\n",
    "        self.labels = None\n",
    "        self.reverse_labels = None\n",
    "        self.order = 0\n",
    "        self.matrix = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def p_row_word(self, order: int, row_word: str, word: str) -> float:\n",
    "        if row_word not in self.reverse_labels or word not in self.reverse_labels:\n",
    "            return 0\n",
    "        row_label = self.reverse_labels[row_word]\n",
    "        word_label = self.reverse_labels[word]\n",
    "\n",
    "        dividend = self.matrix[order, row_label, :][word_label]\n",
    "        divisor = sum(self.matrix[order, row_label, :])\n",
    "\n",
    "        return dividend/divisor if divisor > 0 else 0\n",
    "\n",
    "    def p_col_word(self, order: int, col_word: str, word: str) -> float:\n",
    "        if col_word not in self.reverse_labels or word not in self.reverse_labels:\n",
    "            return 0\n",
    "        col_label = self.reverse_labels[col_word]\n",
    "        word_label = self.reverse_labels[word]\n",
    "\n",
    "        dividend = self.matrix[order, :, col_label][word_label]\n",
    "        divisor = sum(self.matrix[order, :, col_label])\n",
    "\n",
    "        return dividend/divisor if divisor > 0 else 0\n",
    "\n",
    "\n",
    "    def create_matrix(self, tokens: list[list], order: int):\n",
    "        #Setup\n",
    "        self.labels = get_all_words(token_list)\n",
    "        self.reverse_labels = {self.labels[x]: x for x in range(0, len(self.labels))}\n",
    "        self.order = order\n",
    "        self.matrix = np.zeros((order, len(self.labels), len(self.labels)))\n",
    "\n",
    "        #Iteration\n",
    "        for sentence in tqdm(tokens):\n",
    "            for x in range(0, len(sentence)):\n",
    "                word = sentence[x]\n",
    "                if self.verbose:\n",
    "                    print(f\"Word: {word} ({str(self.reverse_labels[word])})\")\n",
    "                for y in range(0, self.order):\n",
    "                    if x+y+1 < len(sentence):\n",
    "                        if self.verbose:\n",
    "                            print(f\"Lookahead {str(y+1)}: {sentence[x+y+1]} ({str(self.reverse_labels[sentence[x+y+1]])})\")\n",
    "                        self.matrix[y][self.reverse_labels[word]][self.reverse_labels[sentence[x+y+1]]] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5416/5416 [00:00<00:00, 56545.47it/s]\n"
     ]
    }
   ],
   "source": [
    "matrix = HMatrix(verbose=False)\n",
    "matrix.create_matrix(token_list, 3) #todo, juypter seems to break when order > 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Class\n",
    "\n",
    "Input a sentence, it will then use the HMatrix to see which path results the most likely outcome for products"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, matrix: HMatrix, tokenizer, raw_sentence: str, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.raw_sentence = tokenizer.tokenize(raw_sentence.lower())\n",
    "        self.sentence = []\n",
    "\n",
    "        # Creating all the blank word classes\n",
    "        for x, word in enumerate(self.raw_sentence):\n",
    "            self.sentence.append(Word(word, x, matrix.order))\n",
    "\n",
    "        # Creating all the forward connections\n",
    "        for x, word in enumerate(self.raw_sentence):\n",
    "            if verbose:\n",
    "                print(f\"--- {word} ---\")\n",
    "            for neighbor in self.sentence:\n",
    "                mapped_pos = self.map_word_pos_to_order(neighbor.position-x)\n",
    "\n",
    "                if mapped_pos[1] is not direction.SELF and mapped_pos[0] < matrix.order: #Looking at itself and order is within scope\n",
    "                    p_value = 0\n",
    "\n",
    "                    if mapped_pos[1] is direction.FORWARD:\n",
    "                        p_value = matrix.p_row_word(mapped_pos[0], word, neighbor.key)\n",
    "                    else:\n",
    "                        p_value = matrix.p_col_word(mapped_pos[0], word, neighbor.key)\n",
    "\n",
    "\n",
    "                    self.sentence[x].neighbors.append(\n",
    "                            {'word': neighbor.key,\n",
    "                             'ref': neighbor,\n",
    "                             'p': p_value,\n",
    "                             'direction': mapped_pos[1].name\n",
    "                            })\n",
    "\n",
    "                    if verbose:\n",
    "                        print(f\"{'  '*mapped_pos[0]}\"\n",
    "                              f\"{word} \"\n",
    "                              f\"-{str(mapped_pos[0])}-> \"\n",
    "                              f\"{neighbor.key} \"\n",
    "                              f\"({str(p_value)})\")\n",
    "\n",
    "\n",
    "\n",
    "    def map_word_pos_to_order(self, position) -> tuple:\n",
    "        #Forward word positions\n",
    "        if position > 0:\n",
    "            return position-1, direction.FORWARD\n",
    "\n",
    "        # Backwards word positions\n",
    "        if position < 0:\n",
    "            return abs(position)-1, direction.BACKWARD\n",
    "\n",
    "        #Pos looking at self\n",
    "        if position == 0:\n",
    "            return -1, direction.SELF\n",
    "\n",
    "\n",
    "\n",
    "class Word:\n",
    "    def __init__(self, key: str, position: int, order: int):\n",
    "        self.key = key\n",
    "        self.position = position\n",
    "        self.matrix_order = order\n",
    "        self.neighbors = []\n",
    "\n",
    "    # This method will find this word's neighbor by taking the words position + an input position, returns None if out of bounds.\n",
    "    def get_neighbor(self, pos):\n",
    "        relative_pos = None\n",
    "        if pos == 0:\n",
    "            return None\n",
    "\n",
    "        if pos > self.matrix_order: #cant look past an order we dont have saved\n",
    "            return None\n",
    "\n",
    "        if pos > 0: #positive lookahead\n",
    "            #if self.position + pos - (self.matrix_order-1)> (self.matrix_order*2+1): #todo these bounds are different\n",
    "            #if len(self.neighbors) < self.matrix_order*2 and len(self.neighbors) < (self.matrix_order + pos):\n",
    "            if (self.position > self.matrix_order and len(self.neighbors) < (self.matrix_order + pos)) or len(self.neighbors) == 0:\n",
    "                relative_pos = None\n",
    "            else:\n",
    "                if self.position < self.matrix_order:\n",
    "                    relative_pos = self.position + (pos-1)\n",
    "                else:\n",
    "                    relative_pos = self.matrix_order + (pos-1)\n",
    "        else: #negative lookahead\n",
    "            if abs(pos) > self.position:\n",
    "                relative_pos = None\n",
    "            else:\n",
    "                if self.position <= self.matrix_order-1:\n",
    "                    relative_pos = (self.matrix_order - abs(pos) + (self.position - self.matrix_order))\n",
    "                else:\n",
    "                    relative_pos = self.matrix_order - abs(pos)\n",
    "\n",
    "        if relative_pos is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.neighbors[relative_pos]\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Word: {self.key} | Position: {str(self.position)}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test = Sentence(matrix, tokenizer, \"logitech g pro x superlight intel i7 8700k\", verbose=False) #logitech g pro x superlight intel i7 8700k"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Order: -3 --\n",
      "logitech -> None\n",
      "g -> None\n",
      "pro -> None\n",
      "x -> logitech\n",
      "superlight -> g\n",
      "intel -> pro\n",
      "i7 -> x\n",
      "8700k -> superlight\n",
      "-- Order: -2 --\n",
      "logitech -> None\n",
      "g -> None\n",
      "pro -> logitech\n",
      "x -> g\n",
      "superlight -> pro\n",
      "intel -> x\n",
      "i7 -> superlight\n",
      "8700k -> intel\n",
      "-- Order: -1 --\n",
      "logitech -> None\n",
      "g -> logitech\n",
      "pro -> g\n",
      "x -> pro\n",
      "superlight -> x\n",
      "intel -> superlight\n",
      "i7 -> intel\n",
      "8700k -> i7\n",
      "-- Order: 0 --\n",
      "logitech -> None\n",
      "g -> None\n",
      "pro -> None\n",
      "x -> None\n",
      "superlight -> None\n",
      "intel -> None\n",
      "i7 -> None\n",
      "8700k -> None\n",
      "-- Order: 1 --\n",
      "logitech -> g\n",
      "g -> pro\n",
      "pro -> x\n",
      "x -> superlight\n",
      "superlight -> intel\n",
      "intel -> i7\n",
      "i7 -> 8700k\n",
      "8700k -> None\n",
      "-- Order: 2 --\n",
      "logitech -> pro\n",
      "g -> x\n",
      "pro -> superlight\n",
      "x -> intel\n",
      "superlight -> i7\n",
      "intel -> 8700k\n",
      "i7 -> None\n",
      "8700k -> None\n",
      "-- Order: 3 --\n",
      "logitech -> x\n",
      "g -> superlight\n",
      "pro -> intel\n",
      "x -> i7\n",
      "superlight -> 8700k\n",
      "intel -> None\n",
      "i7 -> None\n",
      "8700k -> None\n"
     ]
    }
   ],
   "source": [
    "# Use this method to test neighbors and see if they are correct\n",
    "for o in range(-1*matrix.order, matrix.order+1):\n",
    "    print(f\"-- Order: {str(o)} --\")\n",
    "    for x in range(0, len(test.sentence)):\n",
    "        testdata = test.sentence[x].get_neighbor(o)\n",
    "        print(f\"{test.sentence[x].key} -> {testdata['word'] if testdata is not None else None}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def seperate_products(start_word: Word):\n",
    "    products = []\n",
    "\n",
    "# A method to look ahead only 1 word until the next word probability is 0\n",
    "#todo not working\n",
    "def traverse_to_first_order_end(word: Word):\n",
    "    if word.get_neighbor(1) is None:\n",
    "        return word\n",
    "\n",
    "    print(f\"Start: {word.key}\")\n",
    "    neighbor = word.get_neighbor(1)\n",
    "\n",
    "    while neighbor['ref'].get_neighbor(1) is not None and neighbor['ref'].get_neighbor(1)['p'] > 0:\n",
    "        print(f\"Visited: {neighbor['word']}({str(neighbor['p'])})\")\n",
    "\n",
    "        # Go to next neighbor\n",
    "        neighbor = neighbor['ref'].get_neighbor(1)\n",
    "\n",
    "    if neighbor['ref'].get_neighbor(1) is None:\n",
    "        print(f\"EoS: {neighbor['word']}\") # if at end of sentence\n",
    "    else:\n",
    "        print(f\"EoP: {neighbor['word']}\")# if at end of product\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vector Method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Vector:\n",
    "    def __init__(self, items=None):\n",
    "        self.items = items if items is not None else []\n",
    "\n",
    "    def add(self, item, vector):\n",
    "        if len(self.items) == 0:\n",
    "            self.items.append({'items': [item], 'current_vector': vector})\n",
    "        else:\n",
    "            if self.items[-1]['current_vector'] == \"r\": #if current vector is right we dont care about the direction\n",
    "                self.items[-1]['items'].append(item)\n",
    "                self.items[-1]['current_vector'] = vector\n",
    "            elif self.items[-1]['current_vector'] == \"l\":\n",
    "                if vector == 'r': # new item\n",
    "                    self.items.append({'items': [item], 'current_vector': vector})\n",
    "                elif vector == 'l': # old item\n",
    "                    self.items[-1]['items'].append(item)\n",
    "                    self.items[-1]['current_vector'] = vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Take in a sentence, determine if a word should point right or left, then\n",
    "def vector_assign(sentence: list[Word]):\n",
    "    if len(sentence) == 1:\n",
    "        return Vector([sentence[0].key])\n",
    "    v = Vector()\n",
    "    for x, word in enumerate(sentence):\n",
    "        if x == 0: #First word always points right\n",
    "            v.add(word.key, \"r\")\n",
    "            #print(f\"{word.key} -> {sentence[x].get_neighbor(1)['word']}\")\n",
    "        elif x == len(sentence)-1: #end of sentence\n",
    "            v.add(word.key, \"l\")\n",
    "            #print(f\"{sentence[x].get_neighbor(-1)['word']} <- {word.key}\")\n",
    "        else:\n",
    "            #print(f\"Comparing: -1: {str(sentence[x].get_neighbor(-1)['p'])} | 1: {str(sentence[x].get_neighbor(1)['p'])}\")\n",
    "            if sentence[x].get_neighbor(1)['p'] >= sentence[x].get_neighbor(-1)['p']:\n",
    "                v.add(word.key, \"r\")\n",
    "                #print(f\"{word.key}-> {sentence[x].get_neighbor(1)['word']}\")\n",
    "            else:\n",
    "                v.add(word.key, \"l\")\n",
    "                #print(f\"{sentence[x].get_neighbor(-1)['word']} <- {word.key}\")\n",
    "    return v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'items': ['logitech', 'g', 'pro', 'x', 'superlight'], 'current_vector': 'l'},\n {'items': ['intel', 'i7', '8700k'], 'current_vector': 'l'}]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_assign(test.sentence).items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stress Testing The Vector method among all words\n",
    "count = 0\n",
    "for word in token_list[0:100]:\n",
    "    s = Sentence(matrix, tokenizer, \" \".join(word), verbose=False)\n",
    "    print(\"---\")\n",
    "    print(count)\n",
    "    print(\" \".join(word))\n",
    "    print(vector_assign(s.sentence).items)\n",
    "    print(\"---\\n\")\n",
    "    count += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vector_assign(test.sentence).items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "traverse_to_first_order_end(test.sentence[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From word a to word b (order 0) there are the following outcomes:\n",
    "* p(a,b) > 0.0 has 2 outcomes\n",
    "    * b is part of a\n",
    "    * b is NOT part of a, but has been seen in the training data\n",
    "* p(a,b) = 0.0 has 2 outcomes\n",
    "    * b is NOT part of a\n",
    "    * b is a new word\n",
    "        * b is part of a\n",
    "        * b is part of post b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Attempting to use Naive Bayes to classify sentences\n",
    "\n",
    "\n",
    "|   | intel | i7  | 8700k |\n",
    "|-------|-------|-----|-------|\n",
    "| intel | 0     | 1   | 0     |\n",
    "| i7    | 0     | 0   | 1     |\n",
    "| 8700k | 0     | 0   | 0     |\n",
    "\n",
    "P(W_0 | W) = Given the first word is 'intel', what is the probability the word after it will be 'i7'\n",
    "P(W) = probability that a given word is 'intel' =\n",
    "P(W_0) = probability that the next word is 'i7' =\n",
    "P(W | W_0) = given that the next word is 'i7', what is the probability that the first is 'intel'  /(1/2)\n",
    "\n",
    "\n",
    "P(W_0 | W) = ( P(W | W_0) * P(W_0) ) / P(W)\n",
    "\n",
    "P('i7' | 'intel') = ??\n",
    "\n",
    "### Example with more words\n",
    "P('i7' | 'intel') = 1 * .33 / .33 = 1\n",
    "\n",
    "|   | intel | i7  | 8700k |\n",
    "|-------|-------|-----|-------|\n",
    "| intel | 0     | 1   | 1     |\n",
    "| i7    | 0     | 0   | 1     |\n",
    "| 8700k | 0     | 0   | 0     |\n",
    "\n",
    "P(W_0 | W) = Given the first word is 'intel', what is the probability the word after it will be 'i7'\n",
    "P(W) = probability that a given word is 'intel' =\n",
    "P(W_0) = probability that the next word is 'i7' =\n",
    "P(W | W_0) = given that the next word is 'i7', what is the probability that the first is 'intel'\n",
    "\n",
    "\n",
    "P(W_0 | W) = ( P(W | W_0) * P(W_0) ) / P(W)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
