{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from src.classes.database.offer import MongoOffer\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "token_list = [tokenizer.tokenize(x.selling) for x in MongoOffer.objects()]\n",
    "tagged = nltk.pos_tag(token_list[0])\n",
    "\n",
    "tag = Enum('tag', ['BRAND'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def get_all_words(token_list: list[list]) -> list:\n",
    "    words = []\n",
    "    for sentence in token_list:\n",
    "        for word in sentence:\n",
    "            words.append(word)\n",
    "    return sorted(set(words))\n",
    "\n",
    "def next_word_occurrence(key: str, look_ahead: int, tokens: list[list]) -> dict:\n",
    "    counter = defaultdict(int)\n",
    "    for sentence in tokens:\n",
    "        for x in range(0, len(sentence)):\n",
    "            if key == sentence[x]: #if we find the key in a sentence\n",
    "                if (x+look_ahead) < len(sentence):\n",
    "                    counter[sentence[x+look_ahead]] += 1\n",
    "    return counter\n",
    "\n",
    "def p_next_word(given: str, looking: str, look_ahead: int, tokens: list[list]) -> float:\n",
    "    nwo: dict = next_word_occurrence(given, look_ahead, tokens)\n",
    "    return nwo[looking] / sum(nwo.values()) if nwo[looking] != 0 else 0\n",
    "\n",
    "def calculate_all_probabilities(tokens: list[list], look_ahead) -> dict:\n",
    "    all_words = get_all_words(tokens)\n",
    "\n",
    "    #Generating a list of all words\n",
    "    word_canvas = defaultdict()\n",
    "    for word in all_words:\n",
    "        word_canvas[word] = None\n",
    "\n",
    "    p_word = word_canvas.copy()\n",
    "    for word in tqdm(p_word):\n",
    "        p_word[word] = [defaultdict(float) for x in range(0,look_ahead)]\n",
    "        for x in range(0,look_ahead):\n",
    "            for sub_word in all_words:\n",
    "                p = p_next_word(word, sub_word, x+1, tokens)\n",
    "                if p > 0:\n",
    "                    p_word[word][x][sub_word] = p_next_word(word, sub_word, x+1, tokens)\n",
    "                #print(f\"{word} | {str(x)} | {sub_word}: {p_word[word][x][sub_word]}\")\n",
    "    return p_word\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1787/1787 [11:47<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data = calculate_all_probabilities(token_list, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "[defaultdict(float,\n             {'10700k': 0.05555555555555555,\n              '10870h': 0.027777777777777776,\n              '11800h': 0.05555555555555555,\n              '1265u': 0.027777777777777776,\n              '12700h': 0.027777777777777776,\n              '12700k': 0.2222222222222222,\n              '12700t': 0.027777777777777776,\n              '12th': 0.05555555555555555,\n              '13700k': 0.08333333333333333,\n              '16gb': 0.08333333333333333,\n              '6850k': 0.027777777777777776,\n              '7700hq': 0.027777777777777776,\n              '7700k': 0.05555555555555555,\n              '8086k': 0.027777777777777776,\n              '8700k': 0.08333333333333333,\n              '8700t': 0.027777777777777776,\n              '9700': 0.027777777777777776,\n              '9700k': 0.027777777777777776,\n              'upgraded': 0.027777777777777776})]"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['i7']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "# Serializing json\n",
    "json_object = json.dumps(data, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"probabilities.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "class Word:\n",
    "    def __init__(self, word: str):\n",
    "        self.word = word\n",
    "        self.p_of_next_word = [next_word_occurrence(word, x, token_list) for x in range(1,6)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = Word('i5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.p_of_next_word[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "p_of_next_word['word']['looking_for_word'][INDEX HERE OF LOOKAHEAD]\n",
    "return object like {occurrences: 1, probability: 0.5}\n",
    "\n",
    "word1\n",
    "    looking_for1\n",
    "        0: {occurenecs:1, probability: 0.5}\n",
    "        1:  {occurenecs:1, probability: 0.5}\n",
    "        2:  {occurenecs:0, probability: 5}\n",
    "    looking_for2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
